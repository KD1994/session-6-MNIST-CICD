{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from model import MnistNet\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MnistNet                                 [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 8, 12, 12]            --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 26, 26]            72\n",
              "│    └─BatchNorm2d: 2-2                  [1, 8, 26, 26]            16\n",
              "│    └─Dropout: 2-3                      [1, 8, 26, 26]            --\n",
              "│    └─ReLU: 2-4                         [1, 8, 26, 26]            --\n",
              "│    └─Conv2d: 2-5                       [1, 16, 24, 24]           1,152\n",
              "│    └─BatchNorm2d: 2-6                  [1, 16, 24, 24]           32\n",
              "│    └─Dropout: 2-7                      [1, 16, 24, 24]           --\n",
              "│    └─ReLU: 2-8                         [1, 16, 24, 24]           --\n",
              "│    └─Conv2d: 2-9                       [1, 8, 24, 24]            128\n",
              "│    └─MaxPool2d: 2-10                   [1, 8, 12, 12]            --\n",
              "├─Sequential: 1-2                        [1, 16, 6, 6]             --\n",
              "│    └─Conv2d: 2-11                      [1, 16, 10, 10]           1,152\n",
              "│    └─BatchNorm2d: 2-12                 [1, 16, 10, 10]           32\n",
              "│    └─Dropout: 2-13                     [1, 16, 10, 10]           --\n",
              "│    └─ReLU: 2-14                        [1, 16, 10, 10]           --\n",
              "│    └─Conv2d: 2-15                      [1, 16, 8, 8]             2,304\n",
              "│    └─BatchNorm2d: 2-16                 [1, 16, 8, 8]             32\n",
              "│    └─Dropout: 2-17                     [1, 16, 8, 8]             --\n",
              "│    └─ReLU: 2-18                        [1, 16, 8, 8]             --\n",
              "│    └─Conv2d: 2-19                      [1, 16, 6, 6]             2,304\n",
              "│    └─BatchNorm2d: 2-20                 [1, 16, 6, 6]             32\n",
              "│    └─Dropout: 2-21                     [1, 16, 6, 6]             --\n",
              "│    └─ReLU: 2-22                        [1, 16, 6, 6]             --\n",
              "├─AdaptiveAvgPool2d: 1-3                 [1, 16, 1, 1]             --\n",
              "├─Sequential: 1-4                        [1, 10, 1, 1]             --\n",
              "│    └─Conv2d: 2-23                      [1, 10, 1, 1]             160\n",
              "==========================================================================================\n",
              "Total params: 7,416\n",
              "Trainable params: 7,416\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.32\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 0.35\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MnistNet()\n",
        "summary(model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        transforms.RandomAffine(degrees=10,  scale=(0.95, 1.05)),\n",
        "                        # transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'Epoch={epoch} Batch={batch_idx} loss={loss.item():.7f} Accuracy={100. * correct / len(train_loader.dataset):.2f}%')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.7f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=0 Batch=468 loss=0.1062707 Accuracy=90.91%: 100%|██████████| 469/469 [00:10<00:00, 44.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004583, Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=1 Batch=468 loss=0.0760556 Accuracy=97.00%: 100%|██████████| 469/469 [00:10<00:00, 42.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003724, Accuracy: 9850/10000 (98.50%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=2 Batch=468 loss=0.1601883 Accuracy=97.48%: 100%|██████████| 469/469 [00:10<00:00, 43.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003454, Accuracy: 9861/10000 (98.61%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=3 Batch=468 loss=0.0473514 Accuracy=97.66%: 100%|██████████| 469/469 [00:10<00:00, 45.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003399, Accuracy: 9871/10000 (98.71%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=4 Batch=468 loss=0.1223510 Accuracy=97.88%: 100%|██████████| 469/469 [00:10<00:00, 42.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002233, Accuracy: 9913/10000 (99.13%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=5 Batch=468 loss=0.0516343 Accuracy=97.95%: 100%|██████████| 469/469 [00:10<00:00, 43.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002884, Accuracy: 9890/10000 (98.90%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=6 Batch=468 loss=0.0829413 Accuracy=98.00%: 100%|██████████| 469/469 [00:11<00:00, 42.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002314, Accuracy: 9903/10000 (99.03%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=7 Batch=468 loss=0.0218383 Accuracy=98.44%: 100%|██████████| 469/469 [00:11<00:00, 41.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001749, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=8 Batch=468 loss=0.0519804 Accuracy=98.53%: 100%|██████████| 469/469 [00:10<00:00, 45.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001585, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=9 Batch=468 loss=0.0046923 Accuracy=98.50%: 100%|██████████| 469/469 [00:10<00:00, 44.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001731, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=10 Batch=468 loss=0.0186869 Accuracy=98.50%: 100%|██████████| 469/469 [00:11<00:00, 41.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001478, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=11 Batch=468 loss=0.0358143 Accuracy=98.50%: 100%|██████████| 469/469 [00:10<00:00, 43.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001564, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=12 Batch=468 loss=0.0221422 Accuracy=98.57%: 100%|██████████| 469/469 [00:10<00:00, 42.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002138, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=13 Batch=468 loss=0.0318980 Accuracy=98.53%: 100%|██████████| 469/469 [00:11<00:00, 41.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001625, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=14 Batch=468 loss=0.0072799 Accuracy=98.78%: 100%|██████████| 469/469 [00:11<00:00, 42.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001497, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=15 Batch=468 loss=0.0469378 Accuracy=98.81%: 100%|██████████| 469/469 [00:11<00:00, 42.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001564, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=16 Batch=468 loss=0.0120237 Accuracy=98.75%: 100%|██████████| 469/469 [00:11<00:00, 41.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001616, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=17 Batch=468 loss=0.0100550 Accuracy=98.74%: 100%|██████████| 469/469 [00:10<00:00, 43.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001547, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=18 Batch=468 loss=0.0358378 Accuracy=98.79%: 100%|██████████| 469/469 [00:10<00:00, 42.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001385, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=19 Batch=468 loss=0.0402809 Accuracy=98.85%: 100%|██████████| 469/469 [00:11<00:00, 41.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001502, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4000e-03.\n"
          ]
        }
      ],
      "source": [
        "model = MnistNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.015)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4, verbose=True)\n",
        "\n",
        "for epoch in range(20):\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion) \n",
        "    scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
